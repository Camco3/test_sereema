import marimo

__generated_with = "0.11.21"
app = marimo.App(width="medium")


@app.cell
def _():
    from datetime import datetime, timedelta, timezone

    import marimo as mo
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    import polars as pl
    import scipy.stats as stats
    return datetime, go, mo, np, pd, pl, plt, px, stats, timedelta, timezone


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        # Introduction

        The following libs are pre-installed:

        - numpy
        - scipy
        - pandas
        - polars
        - matplotlib
        - plotly

        Feel free to use others libs if needed.
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        # Task 1: Data Extraction and Consolidation from SCADA Files

        In the wind enery world, [SCADA](https://en.wikipedia.org/wiki/SCADA) files are time series generated by a wind turbine. They are generally in [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) format, but unfortunately no standard exists, neither for the file format nor the columns names.

        Exemple of SCADA file ([source](https://www.kaggle.com/datasets/berkerisen/wind-turbine-scada-dataset?resource=download&select=T1.csv)):

        `csv
        Date/Time,LV ActivePower (kW),Wind Speed (m/s),Theoretical_Power_Curve (KWh),Wind Direction (°)
        01 01 2018 00:00,380.047790527343,5.31133604049682,416.328907824861,259.994903564453
        01 01 2018 00:10,453.76919555664,5.67216682434082,519.917511061494,268.64111328125
        01 01 2018 00:20,306.376586914062,5.21603679656982,390.900015810951,272.564788818359
        01 01 2018 00:30,419.645904541015,5.65967416763305,516.127568975674,271.258087158203
        01 01 2018 00:40,380.650695800781,5.57794094085693,491.702971953588,265.674285888671
        01 01 2018 00:50,402.391998291015,5.60405206680297,499.436385024805,264.57861328125
        01 01 2018 01:00,447.605712890625,5.79300785064697,557.372363290225,266.163604736328
        01 01 2018 01:10,387.2421875,5.30604982376098,414.898178826186,257.949493408203
        01 01 2018 01:20,463.651214599609,5.58462905883789,493.677652137077,253.480697631835
        `

        For this task, you have to load the essential data from SCADA files into a DataFrame (or equivalent) for a subsequent analysis of wind turbine performance.

        You will have to use the SCADA files from the dataedpdata/edp/ folder:

        - scada_T01_2016.csv
        - scada_T01_2017.csv
        - scada_T06_2016.csv
        - scada_T06_2017.csv
        - scada_T07_2016.csv
        - scada_T07_2017.csv
        - scada_T11_2016.csv
        - scada_T11_2017.csv

        Each file contains 1 year of data from an Enercon E33 wind turbine.

        The extracted data should include only turbine ID, timestamp, average wind speed, absolute average wind direction, and total active power for the 2 years and 4 turbines.

        Output exemple:
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.image("./images/task1_load_dataframe.png")
    return


@app.cell
def _(pl):
    # Files informations
    files_to_open = ['scada_T01_2016.csv','scada_T01_2017.csv', 'scada_T06_2016.csv', 'scada_T06_2017.csv', 
                     'scada_T07_2016.csv','scada_T07_2017.csv', 'scada_T11_2016.csv', 'scada_T11_2017.csv']
    path = r'data\\edp\\'

    # Data preloading information
    target_column_types = {
        "Turbine_ID": pl.Utf8,  
        "Timestamp": pl.Datetime, 
        "Amb_WindSpeed_Avg": pl.Float64,
        "Amb_WindDir_Abs_Avg": pl.Float64,
        "Prod_LatestAvg_TotActPwr": pl.Float64
    }

    # preload data only for specific columns with specified type
    dfs = [pl.scan_csv(source=path+f, schema_overrides=target_column_types).select(list(target_column_types.keys())) 
           for f in files_to_open]

    # load data and concat then into dataframe
    df = pl.concat(dfs).collect()

    # Rename columns 
    update_cols = {"Turbine_ID": 'turbine',  
                   "Timestamp": 'timestamp',
                   "Amb_WindSpeed_Avg": 'wind_speed',
                   "Amb_WindDir_Abs_Avg": 'wind_direction',
                   "Prod_LatestAvg_TotActPwr": 'active_power'
                }
    df=df.rename(update_cols)
    df
    return df, dfs, files_to_open, path, target_column_types, update_cols


@app.cell
def _(df):
    # Check any missing data
    df.null_count()
    return


@app.cell
def _(df):
    # See description of data 
    df.describe()
    return


@app.cell
def _(df):
    df_length = df.shape[0]
    print(f'Le fichier contient {df_length} enregistrement')
    nbr_duplicates = df_length - df.unique(keep="first").shape[0] 
    print(f'Il y a {nbr_duplicates} données dupliquées')
    return df_length, nbr_duplicates


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        # Task 2 - Power Curve Visualization for Wind Turbine Performance Analysis

        A power curve is a graphical representation of a wind turbine's power output as a function of wind speed. Visualizing the power curve allows for quick assessment of turbine performance and identification of potential anomalies.

        Your objective is to generate a scatter plot of active power versus wind speed for the  wind turbine T01 over the period \[2016-12-21; 2017-01-08\[.

        Output exemple:
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.image("./images/task2_scatter.png")
    return


@app.cell
def _(datetime):
    import regex as re
    # test if string is a correct date format
    def validate_datetime_format(func):
        def wrapper(date_str):
            pattern = r"^(\d{4}-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01]))( (\d{2}:[0-5][0-9]:[0-5][0-9]))?$"
            if not re.match(pattern, date_str):
                raise ValueError(f"Invalid date format or invalid date: {date_str}, date must be of shape %Y-%m-%d %H:%M:%S or %Y-%m-%d.")
            return func(date_str)
        return wrapper

    @validate_datetime_format
    def convert_string_to_datetime(str):
        """ Function to convert string to datetime format, string date format must be of time %Y-%m-%d %H:%M:%S or %Y-%m-%d"""
        try: 
            converted_str = datetime.strptime(str, "%Y-%m-%d %H:%M:%S")
        except ValueError: 
            converted_str=datetime.strptime(str, "%Y-%m-%d").replace(hour=0, minute=0, second=0)
        return converted_str
    return convert_string_to_datetime, re, validate_datetime_format


@app.cell
def _(convert_string_to_datetime, df, pl):
    # Definition of new dataframe for task2 
    C1 = pl.col('turbine')=='T01'
    C2 = pl.col('timestamp') >= convert_string_to_datetime('2016-12-21')
    C3 = pl.col('timestamp') < convert_string_to_datetime('2017-01-08')
    df_task2 = df.filter(C1 & (C2 & C3))
    df_task2.describe()
    return C1, C2, C3, df_task2


@app.cell
def _(df_task2, go):
    # Create plot2 which will be completed in task 3
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df_task2['wind_speed'], y=df_task2['active_power'], mode='markers', name="Measured data for T01"))
    fig.update_layout(
        xaxis_title="Wind speed (m.s<sup>-1</sup>)",
        yaxis_title="Active power (W)",
        title="Active power vs wind speed for T01",
        title_x=0.5,  
        title_font=dict(size=20, family='Arial', weight='bold')
    )
    fig.show()
    return (fig,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        # Task 3 - Enhanced Power Curve Visualization

        Your objective is to enhance the existing power curve visualization by adding the average active power for wind speed bins of 1 m/s width.

        Also add the manufacturer reference power curve to the plot. You can find the reference power curve in the document docsE≠rcontechnicaldatabrochure.pdfdocs/Enercon_technical_data_brochure.pdf.


        Output exemple:
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.image("./images/task3_plot_avg.png")
    return


@app.cell
def _(np):
    # Get technical data from docs/Enercon_technical_data_brochure.pdf for an Enercon E33
    # Power given in kW are converted in W to fit with actual unit 
    x_ref = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
    y_ref_active = [0, 0, 5000, 13700, 30000, 55000, 92000, 138000, 196000, 250000, 292800, 320000, 335000, 335000, 335000, 335000, 335000, 335000, 335000, 335000, 335000, 335000, 335000, 335000, 335000]

    cp = [0, 0, 0.35, 0.40, 0.45, 0.47, 0.50, 0.50, 0.50, 0.47, 0.41, 0.35, 0.28, 0.23, 0.18, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07, 0.06,
         0.05, 0.05, 0.04]
    rho = 1.225  # Air density (kg/m³)
    R = 33.4/2  # Rotor radius (m)
    A = np.pi * R**2  # Swept area (m²)
    P_max = 335000  # Maximal power (W)

    # Calculation of the theoretical power available from wind power 
    #y_ref_active = [0.5 * rho * A * V**3 * coeff for V, coeff in zip(x_ref, cp)]
    # y_ref_power is the wind power (P_vent) with limitation to 335 kW
    y_ref_power = [min(0.5 * rho * A * V**3, P_max) for V in x_ref]
    return A, P_max, R, cp, rho, x_ref, y_ref_active, y_ref_power


@app.cell
def _(df_task2, pl):
    # Perform average active power for 1m.s-1 range wind speed.
    df_avg = df_task2.with_columns(pl.col('wind_speed').round().alias('wind_speed_range'))

    df_avg=df_avg.group_by('wind_speed_range').agg(
        pl.col('active_power').mean().alias('average_total_active_power_over_ranges')
    ).sort('wind_speed_range')
    df_avg
    return (df_avg,)


@app.cell
def _(df_task2):
    df_task2.describe()
    return


@app.cell
def _(df_avg, fig, go, x_ref, y_ref_active, y_ref_power):
    fig.add_trace(go.Scatter(x=x_ref, y=y_ref_active, mode='lines+markers', name="Reference active manufacturer", line=dict(color='black'),  
        marker=dict(color='black', size=8, symbol='circle')))
    fig.add_trace(go.Scatter(x=df_avg['wind_speed_range'], y=df_avg['average_total_active_power_over_ranges'], mode='lines+markers', name="Average",  line=dict(color='red'),  # Ligne verte en pointillés
        marker=dict(color='red', size=8, symbol='circle')))
    fig.add_trace(go.Scatter(x=x_ref, y=y_ref_power, mode='lines+markers', name="Reference of wind power with threshold of 350kW", line=dict(color='green'),  
        marker=dict(color='green', size=8, symbol='circle')))
    fig.update_layout(
        xaxis_title="Wind speed (m.s<sup>-1</sup>)", yaxis_title="Active power (W)"
    )
    return


@app.cell
def _(mo):
    mo.md(
        """
        ## Commentaires: 
        La courbe ReferenceactivemaνfacturerReference active manufacturer semble présenter des incohérences, étant donné que, théoriquement, la valeur de la puissance active ne peut pas être inférieure aux valeurs mesurées. J'ai pensé à plusieurs explications:

        * Il est également possible qu'il y ait une erreur dans les données que j'ai calculées ou représentées.
        * Un autre paramètre pourrait éventuellement m'avoir échappé à la prise en compte dans cette analyse.
        * Les données de puissance (P) du tableau de référence pour l'Enercon E33 ne correspondent peut-être pas à la puissance active attendue. Toutefois, après un calcul avec la formule $P_{active}=P_{vent}.Cp$, les données du tableau semblent bien correspondre à une puissance active. Est-il possible qu'il s'agisse d'une autre valeur de puissance demandée ?
        * Enfin, même si cela parait très peu probable est-il possible qu'il y ait une erreur dans les données du tableau de référence?
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        # Task 4 - Monthly Production Analysis by Turbine

        Tracking the monthly production of each turbine is essential for monitoring wind farm performance and identifying trends. This task requires you to aggregate turbine production data by month and visualize the monthly production of each turbine using a line plot.

        Output exemple:
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.image("images/task4_monthly_production.png")
    return


@app.cell
def _(df, pl):
    # Creation of a new dataframe for task4
    df_task4 = df.select(["turbine", "timestamp", "active_power"])
    # Create month-year column
    df_task4 = df_task4.with_columns(pl.col('timestamp').dt.strftime('%Y-%m').alias('date_month_yr'))
    # sum over hours to have active power in Wh to make column clearer however anomalies might be taken into account
    df_task4 = df_task4.with_columns(pl.col("timestamp").dt.strftime("%Y-%m-%d %H:00:00").alias("hour"))
    # 183 anomalies, values sometimes exceeding 6 measurements per hour.  
    # Considered cases:  
    # - If there are fewer than 6 values recorded per hours, the missing X values are added as the average of the previously measured values.  
    # - If there are more than 6 values recorded per hours, the average of the measured values is calculated and multiplied by 6.  

    # Aggregate all active power values at same hours 
    df_task4 = df_task4.group_by(["turbine", "hour", "date_month_yr"]).agg(
            pl.col("active_power").alias("values"))
    def sum_energy_over_hours_with_outliers_corrected(values):
        num_values = len(values)
        if num_values < 6:
            # Add 6-X times the mean values of the X record value 
            mean_value = values.mean()
            values = values.to_list() + [mean_value] * (6 - num_values)  
        elif num_values > 6:
            # Get the mean values of the X record and multiply by 6 to get the sum over an hour 
            mean_value = values.mean()
            values = [mean_value] * 6  
        return sum(values) 

    df_task4 = df_task4.with_columns(
            pl.col("values").map_elements(sum_energy_over_hours_with_outliers_corrected, return_dtype=pl.Float64).alias("energy")
        )

    df_task4 = df_task4.drop("values")
    # Sum energy over month for each turbine
    df_task4=df_task4.group_by(['turbine','date_month_yr']).agg(
        pl.col('energy').sum().alias('energy')
    ).sort('date_month_yr')
    df_task4.head()
    return df_task4, sum_energy_over_hours_with_outliers_corrected


@app.cell
def _(df_task4, px):
    fig2 = px.line(df_task4,
    x="date_month_yr", y="energy", color='turbine', markers=False)
    fig2.update_layout(
        xaxis_title="Date", yaxis_title="Energy (Wh)"
    )
    fig2.show()
    return (fig2,)


@app.cell
def _(mo):
    mo.md(
        """
        ## Commentaire 
        Il y a un facteur 6 entre le graphique d'exemple et celui que j'ai produit, fallait-il moyenner l'energie par heure avant d'aggréger les données par mois? Dans ce cas l'energie mesurée toute les 10 minutes correspond à une estimation de l'energie produite par heure?
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        # Task 5 - Seasonal Wind Direction Analysis for Wind Turbine T06

        Your objective is to create four polar bar plots, one for each season (Winter, Spring, Summer, and Fall), showing the frequency distribution of wind direction for wind turbine T06. Use 30° bins for the wind direction.

        Output exemple:
        """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.image("images/task5_seasonal.png")
    return


@app.cell
def _(mo):
    mo.md(
        r"""
        ## Season dates for 2016 and 2017 (source: IMCEE)

        | year | season | date |
        | :--- | :---  | :--- |
        |2016 | spring | 20-03-2016 04:30:00 |
        |2016 | summer | 20-05-2016 22:35:00 |
        |2016 | fall   | 22-09-2016 14:21:00 |
        |2016 | winter | 21-12-2016 10:44:00 |
        |2017 | spring | 20-03-2017 10:28:00 |
        |2017 | summer | 21-05-2017 04:24:00 |
        |2017 | fall   | 22-09-2017 20:02:00 |
        |2017 | winter | 21-12-2017 16:28:00 |
        """
    )
    return


@app.cell
def _(convert_string_to_datetime, np):
    from bisect import bisect
    # Create new colonne with season associated to given date

    date_array = np.array(['2016-03-20 04:30:00', '2016-06-20 22:35:00', '2016-09-22 14:21:00',
                           '2016-12-21 10:44:00', '2017-03-20 10:28:00', '2017-06-21 04:24:00', '2017-09-22 20:02:00', 
                            '2017-12-21 16:28:00'])
    date_array = np.array([convert_string_to_datetime(d) for d in date_array])
    season_lst = ['winter', 'spring', 'summer', 'fall','winter', 'spring', 'summer', 'fall', 'winter']
    dict_season = {k: v for k, v in zip(date_array, season_lst)}

    def associate_season_to_datetime(date, date_array, season_lst):
        """ Function to associate a season to a given date.

            Parameter: 
            ---------
            date : datetime
                date to get season from 
            date_array : numpy.ndarray 
                array with season dates 
            season_lst : list
                list of corresponding string season from season date. len(date_array) = len(season_lst)-1, 
                make sure to add a first season before the first season date. 

            Returns:
            -------
            str
        """
        idx = bisect(date_array, date)  
        return season_lst[idx]

    # tests
    dict_test = {'2016-03-01 00:00:00': 'winter', 
                 '2016-03-20 04:30:00': 'spring',
                 '2017-07-23 04:24:00': 'summer',
                 '2016-10-22 20:02:00': 'fall',
                 '2017-12-31 16:28:00': 'winter' }
    for k, v in dict_test.items():
        assert associate_season_to_datetime(convert_string_to_datetime(k), date_array, season_lst) == v
    return (
        associate_season_to_datetime,
        bisect,
        date_array,
        dict_season,
        dict_test,
        k,
        season_lst,
        v,
    )


@app.cell
def _(associate_season_to_datetime, date_array, df, np, pl, season_lst):
    df_task5 = df.filter(pl.col('turbine')=='T06')
    df_task5 = df_task5.with_columns(pl.col('timestamp').map_elements(lambda x: associate_season_to_datetime(x, date_array, season_lst),
                                                                     return_dtype=pl.Utf8).alias('season'))
    # 30° bin
    bins = np.arange(0, 361, 30)
    df_task5=df_task5.with_columns(
        pl.col("wind_direction").cut(breaks=bins,  left_closed=True).alias("wind_dir_bin")
    )
    return bins, df_task5


@app.cell
def _(bins, df_task5, go, pl):
    from plotly.subplots import make_subplots
    colors = ["blue", "red", "green", "purple"]

    fig4 = make_subplots(
        rows=2, cols=2,  
        subplot_titles=["Winter", "Spring", "Summer", "Fall"],
        specs=[[{"type": "polar"}, {"type": "polar"}], 
               [{"type": "polar"}, {"type": "polar"}]]
    )


    bin_labels = [f"{b}°" for b in bins[:-1]]  # Labels des bins

    # Ajouter un tracé polaire pour chaque saison
    for i, (season, color) in enumerate(zip(df_task5["season"].unique(), colors)):
        # Filtrer les données pour la saison en cours
        df_season = df_task5.filter(pl.col("season") == season)

        # Calculer la fréquence des directions du vent dans les bins de 30°
        total_count = df_season.shape[0]
        frequency_bin = df_season.group_by("wind_dir_bin").agg(pl.len().alias("count"))

        # Calculer la fréquence en divisant par le total des données
        frequency_bin = frequency_bin.with_columns((frequency_bin['count'] / total_count).alias('frequency'))
        frequency_bin = frequency_bin.sort("wind_dir_bin")

        # Ajouter le tracé en barres polaires pour cette saison
        fig4.add_trace(
            go.Barpolar(
                r=frequency_bin['frequency'],  # Fréquences de chaque bin
                theta=bin_labels,  # Labels des bins en degrés
                name=season,
                marker=dict(color=color),
                opacity=0.6  # Transparence
            ),
            row=(i // 2) + 1, col=(i % 2) + 1  # Placement dans la grille 2x2
        )

    # Personnalisation des axes et de la disposition
    fig4.update_layout(
        title="Distribution of the wind direction per seasons",
        title_x=0.5,  
        title_font=dict(size=20, family='Arial', weight='bold'),
        showlegend=True,  # Pas de légende globale
        height=600, width=600,
        polar1=dict(angularaxis=dict(rotation=90, direction='clockwise')),
        polar2=dict(angularaxis=dict(rotation=90, direction='clockwise')),
        polar3=dict(angularaxis=dict(rotation=90, direction='clockwise')),
        polar4=dict(angularaxis=dict(rotation=90, direction='clockwise')),
         annotations=[
            # Déplacer les titres des subplots un peu plus haut
            dict(
                x=0.25, y=1.05,  # Ajuster x et y pour chaque titre
                xref="paper", yref="paper",
                text="Winter", showarrow=False, font=dict(size=14)
            ),
            dict(
                x=0.75, y=1.05,
                xref="paper", yref="paper",
                text="Spring", showarrow=False, font=dict(size=14)
            ),
            dict(
                x=0.25, y=0.45,
                xref="paper", yref="paper",
                text="Summer", showarrow=False, font=dict(size=14)
            ),
            dict(
                x=0.75, y=0.45,
                xref="paper", yref="paper",
                text="Fall", showarrow=False, font=dict(size=14)
            )
        ]
    )

    # Afficher le graphique interactif
    fig4.show()
    return (
        bin_labels,
        color,
        colors,
        df_season,
        fig4,
        frequency_bin,
        i,
        make_subplots,
        season,
        total_count,
    )


app._unparsable_cell(
    r"""
    ## Commentaire 
    Les graphiques ne sont pas tout à fait identiques, mais cela peut aussi être dû au choix des dates des différentes saisons.
    """,
    name="_"
)


if __name__ == "__main__":
    app.run()
